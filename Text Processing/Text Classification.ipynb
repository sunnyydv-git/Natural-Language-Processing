{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb65db4-3a4f-4eb1-8f28-01ffdf3d982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7168b026-00b6-4812-9340-e201b52a450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            message\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n",
      "label\n",
      "0    4825\n",
      "1     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding = \"latin-1\")\n",
    "\n",
    "df = df.iloc[:, :2]   \n",
    "df.columns = [\"label\", \"message\"]\n",
    "\n",
    "df[\"label\"]  = df[\"label\"].map({\"ham\":0, \"spam\":1})\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64676e3-8433-4ae9-ba6a-190b345b98a8",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3d3427-eb36-4952-86b2-f6cda416a461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sunny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sunny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f726d1a-ee1b-47dc-8360-44773177914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            message  \\\n",
      "0      0  Go until jurong point, crazy.. Available only ...   \n",
      "1      0                      Ok lar... Joking wif u oni...   \n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3      0  U dun say so early hor... U c already then say...   \n",
      "4      0  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  go jurong point crazy available bugis n great ...  \n",
      "1                            ok lar joking wif u oni  \n",
      "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
      "3                u dun say early hor u c already say  \n",
      "4        nah dont think goes usf lives around though  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"message\"].apply(preprocess_text)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523972d-06d5-4d95-b283-c508acf46fc5",
   "metadata": {},
   "source": [
    "#### Text Classification using Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704f7824-a937-4468-8bad-dd8e92af28c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (BoW): 0.9802690582959641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.97      0.88      0.92       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline (BoW + Naive Bayes)\n",
    "pipeline_bow = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline_bow.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipeline_bow.predict(X_test)\n",
    "print(\"Accuracy (BoW):\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0921b0e-20e4-4a3a-9a26-342ac376701b",
   "metadata": {},
   "source": [
    "#### Text Classification using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db789fae-2998-453b-998b-dffba5bd6364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (TF-IDF): 0.967713004484305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.76      0.86       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline (TF-IDF + Naive Bayes)\n",
    "pipeline_tfidf = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline_tfidf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_tfidf = pipeline_tfidf.predict(X_test)\n",
    "print(\"Accuracy (TF-IDF):\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(classification_report(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40356857-fabd-4f78-94fc-a5ad1129e9f8",
   "metadata": {},
   "source": [
    "#### Text Classification using Word Embeddings (Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c4bf1a5-5655-48cc-a4dc-07da70e03884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mobile', 0.9997726082801819), ('txt', 0.9997410178184509), ('ur', 0.99972003698349), ('2', 0.9997028708457947), ('reply', 0.9996951222419739), ('phone', 0.9996748566627502), ('get', 0.9996717572212219), ('text', 0.9996702075004578), ('n', 0.9996155500411987), ('call', 0.9996111989021301)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize sentences\n",
    "sentences = [text.split() for text in df[\"cleaned_text\"]]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "print(word2vec_model.wv.most_similar(\"free\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
